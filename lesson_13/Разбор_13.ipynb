{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В практической части задания мы сравнили распределения выходов решающей функции (оценка вероятности) SVM и LogReg. Обычно у гистограммы для LogReg хвосты тяжелее, чем у гистограммы для SVM. С чем это может быть связано?*: \n",
    "\n",
    "1. Это никак нельзя объяснить, просто эмпирический факт.\n",
    "2. Дело в функционалах, на которые обучаются модели. SVM достаточно сделать отступ равным 1, в том время как LogReg максимизирует отступ\n",
    "3. Потому что SVM плохо оценивает вероятности, а LogReg - хорошо\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** пояснение в самом ответе\n",
    "\n",
    "_______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Выберите верное утверждение о SVM и Logreg*: \n",
    "\n",
    "1.\tОткалиброванный SVM всегда оценивает вероятности лучше, чем LogReg\n",
    "2.\tУ SVM в среднем будет немного более высокая accuracy, чем у LogReg\n",
    "3.\tНельзя сказать, что будет лучше по какой-либо метрике. Просто одна модель оценивает вероятность, а другая - нет\n",
    "4.\tSVM обучается быстрее, чем LogReg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Из-за того, что LogReg максимизирует свою уверенность (старается корректно оценивать вероятности), ему может быть выгодно ошибаться на объектах, близких к разделяющей гиперплоскости. Он как бы более склонен подстраиваться под \"далекие\" объекты в признаковом пространств.\n",
    "\n",
    "_______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пусть у нас есть выборка из 10 объектов и 5 признаков. Обучаем SVM в общем виде. Сколько обучаемых параметров будет у модели?*: \n",
    "\n",
    "1.\t11\n",
    "2.\t5\n",
    "3.\t50\n",
    "4.\t16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 4)** Параметр регуляризации $\\lambda$, 10 параметров $\\xi_i$ для каждого объекта (регулируют отступ по объекту от плоскости) и сами 5 признаков (и соотвествующие им коэффициенты $\\beta_j$), описывающих гиперплоскость.\n",
    "\n",
    "_______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку на тест и трейн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('HasDetections', axis=1)\n",
    "y = data['HasDetections']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите LogReg и SVM с помощью классов `LogisticRegression` и `LinearSVC`. Добавьте шаг стандартизации данных в пайплайны. Для разнообразия, возьмем `MinMaxScaler`. Пайплайны запишем в переменные `pipe_lr` и `pipe_svm` соответственно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipe_lr = Pipeline([('lr_scaler', MinMaxScaler()), \n",
    "                    ('lr_estimator', LogisticRegression())])\n",
    "\n",
    "pipe_svm = Pipeline([('lr_scaler', MinMaxScaler()), \n",
    "                    ('svm_estimator', LinearSVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте ROC для обеих моделей, посчитайте AUC. Конечно же, обучение проводите на трейне, а замеры - на тесте.\n",
    "\n",
    "Заметьте! Классическая реализация `SVM`, как и в лекциях, не дает никакой оценки вероятности. Чтобы трансформировать выходы в вероятности, на практике мы использовали функцию-сигмоиду. Здесь предлагаем Вам трансформировать выходы `decision_function` в вероятности пропорциональным способом.\n",
    "\n",
    "Например, вы обучили `SVM`, и на тестовых данных модель выдала следующие выходы `decision_function`:\n",
    "\n",
    "(-10, -5, 0, +2, +10, +15)\n",
    "\n",
    "Для каждого числа необходимо сделать преобразование в выражение вида `P(y = +1 | x)`.\n",
    "\n",
    "С одной стороны, отрицательный знак числа будет сигнализировать нам о том, что `P(y = +1 | x) < 0.5`.\n",
    "\n",
    "Тогда положительный о том, что `P(y = +1 | x) > 0.5`. \n",
    "\n",
    "С другой стороны, для тех объектов, в которых модель уверена больше всего, положим краевые вероятности. Для примера выше:\n",
    "\n",
    "`P(y = +1 | -10) = 0`, `P(y = +1 | +15) = 1`. Для всех промежуточных объектов применим пропорциональное преобразование. Например:\n",
    "\n",
    "$$\n",
    "P(y = +1 | -5) = \\frac{|-5|}{|-10|} \\cdot 0.5\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y = +1 | +2) = \\frac{|+2|}{|+15|} \\cdot 0.5 + 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Обучаем модели на трейне\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "pipe_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### С изображением рок-кривой для ЛогРега не будет проблем:\n",
    "\n",
    "preds_lr = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(y_test, preds_lr)\n",
    "roc_display1 = RocCurveDisplay(fpr=fpr1, tpr=tpr1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### А для того, чтобы построить и изобразить рок-кривую для SVM, придется\n",
    "### в начале преобразовать выходы pipe_svm.decision_function\n",
    "\n",
    "decision_preds = pipe_svm.decision_function(X_test)\n",
    "\n",
    "min_pred = min(decision_preds)\n",
    "max_pred = max(decision_preds)\n",
    "\n",
    "\n",
    "preds_svm = [-abs(x-min_pred)/min_pred*0.5 \n",
    "             if x <= 0 \n",
    "             else abs(x/max_pred)*0.5+0.5 \n",
    "             for x in decision_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr2, tpr2, _ = roc_curve(y_test, preds_svm)\n",
    "roc_display2 = RocCurveDisplay(fpr=fpr2, tpr=tpr2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc \n",
    "\n",
    "print('LogReg auc =', auc(fpr1, tpr1))\n",
    "print('SVM auc =', auc(fpr2, tpr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте калибровочные кривые для обеих моделей. Методом from_estimator для svm воспользоваться не получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "prob_true_lr, prob_pred_lr = calibration_curve(y_test,\n",
    "                                               preds_lr,\n",
    "                                               n_bins=5)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "plt.plot(prob_true_lr, prob_pred_lr)\n",
    "plt.plot(np.linspace(0, 1, 5), np.linspace(0, 1, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "prob_true_svm, prob_pred_svm = calibration_curve(y_test,\n",
    "                                               preds_svm,\n",
    "                                               n_bins=5)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "plt.plot(prob_true_svm, prob_pred_svm)\n",
    "plt.plot(np.linspace(0, 1, 5), np.linspace(0, 1, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая калибровочная кривая ближе к диагонали? Откалибруйте SVM способом как в практике и изобразите новую кривую!\n",
    "\n",
    "-- *Конечно же, кривая LR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Калибровка\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "plats_calibration = CalibratedClassifierCV(pipe_svm,\n",
    "                                           cv=3,\n",
    "                                           method='sigmoid').fit(X_train, y_train)\n",
    "\n",
    "plats_calibration_preds = plats_calibration.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Новая кривая\n",
    "\n",
    "prob_true_svm, prob_pred_svm = calibration_curve(y_test,\n",
    "                                                 plats_calibration_preds,\n",
    "                                                 n_bins=5)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "plt.plot(prob_true_svm, prob_pred_svm)\n",
    "plt.plot(np.linspace(0, 1, 5), np.linspace(0, 1, 5))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "908564da9541f9d26d1af86ee6b322ed44d6c94bc2ca2345fbed60c52c45f160"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
