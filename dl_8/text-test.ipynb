{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-03-15T14:46:34.648465Z",
     "iopub.execute_input": "2023-03-15T14:46:34.650081Z",
     "iopub.status.idle": "2023-03-15T14:46:34.666214Z",
     "shell.execute_reply.started": "2023-03-15T14:46:34.650021Z",
     "shell.execute_reply": "2023-03-15T14:46:34.664804Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:46:34.672370Z",
     "iopub.execute_input": "2023-03-15T14:46:34.672821Z",
     "iopub.status.idle": "2023-03-15T14:46:35.853316Z",
     "shell.execute_reply.started": "2023-03-15T14:46:34.672766Z",
     "shell.execute_reply": "2023-03-15T14:46:35.851907Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "fasttext = api.load('glove-twitter-25')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:46:35.856289Z",
     "iopub.execute_input": "2023-03-15T14:46:35.856846Z",
     "iopub.status.idle": "2023-03-15T14:47:09.576987Z",
     "shell.execute_reply.started": "2023-03-15T14:46:35.856806Z",
     "shell.execute_reply": "2023-03-15T14:47:09.575253Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext.most_similar(positive=['man'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:09.578566Z",
     "iopub.execute_input": "2023-03-15T14:47:09.579007Z",
     "iopub.status.idle": "2023-03-15T14:47:09.713706Z",
     "shell.execute_reply.started": "2023-03-15T14:47:09.578967Z",
     "shell.execute_reply": "2023-03-15T14:47:09.711759Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, texts, min_freq: int = 10):\n",
    "        text = ' '.join(texts)\n",
    "\n",
    "        text = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", text)\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "        while '  ' in text:\n",
    "            text = text.replace('  ', ' ')\n",
    "\n",
    "        words = text.strip().lower().split()\n",
    "\n",
    "        c = Counter(words)\n",
    "\n",
    "        self.vocabulary = list(set([word for word in words if c[word] >= min_freq]))\n",
    "        self.vocabulary.append('<unk>')\n",
    "        self._idx2word = {i: word for i, word in enumerate(self.vocabulary)}\n",
    "        self._word2idx = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocabulary\n",
    "\n",
    "    def idx2word(self, idx: int):\n",
    "        if idx not in self._idx2word:\n",
    "            return '<unk>'\n",
    "\n",
    "        return self._idx2word[idx]\n",
    "\n",
    "    def word2idx(self, word: str):\n",
    "        word = word.lower()\n",
    "        if word not in self._word2idx:\n",
    "            return self._word2idx['<unk>']\n",
    "\n",
    "        return self._word2idx[word]\n",
    "    \n",
    "    def encode(self, text):\n",
    "        result = []\n",
    "\n",
    "        for word in text.split():\n",
    "            result.append(self.word2idx(word))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def build_vectors(self, fasttext):\n",
    "        vectors = []\n",
    "        \n",
    "        for word in self.vocabulary:\n",
    "            if fasttext.has_index_for(word):\n",
    "                vectors.append(fasttext[word])\n",
    "            else:\n",
    "                vectors.append(np.zeros(25))\n",
    "\n",
    "        return np.stack(vectors)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:09.715922Z",
     "iopub.execute_input": "2023-03-15T14:47:09.716437Z",
     "iopub.status.idle": "2023-03-15T14:47:09.793671Z",
     "shell.execute_reply.started": "2023-03-15T14:47:09.716384Z",
     "shell.execute_reply": "2023-03-15T14:47:09.792640Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:09.795360Z",
     "iopub.execute_input": "2023-03-15T14:47:09.795849Z",
     "iopub.status.idle": "2023-03-15T14:47:10.512351Z",
     "shell.execute_reply.started": "2023-03-15T14:47:09.795799Z",
     "shell.execute_reply": "2023-03-15T14:47:10.510927Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train, df_test = np.split(df, [45000], axis=0)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:10.517110Z",
     "iopub.execute_input": "2023-03-15T14:47:10.517632Z",
     "iopub.status.idle": "2023-03-15T14:47:10.529166Z",
     "shell.execute_reply.started": "2023-03-15T14:47:10.517595Z",
     "shell.execute_reply": "2023-03-15T14:47:10.527607Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class IMDB(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        \n",
    "        texts = self.df['review'].values\n",
    "\n",
    "        self.vocab = Vocabulary(texts, min_freq=5)\n",
    "\n",
    "        self.label2idx = {'positive': 0, 'negative': 1}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df['review'].loc[idx]\n",
    "        label = self.label2idx[self.df['sentiment'].loc[idx]]\n",
    "\n",
    "        text = torch.LongTensor(self.vocab.encode(text))\n",
    "        label = torch.FloatTensor([label])\n",
    "\n",
    "        return text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:10.530906Z",
     "iopub.execute_input": "2023-03-15T14:47:10.531407Z",
     "iopub.status.idle": "2023-03-15T14:47:10.545557Z",
     "shell.execute_reply.started": "2023-03-15T14:47:10.531367Z",
     "shell.execute_reply": "2023-03-15T14:47:10.543858Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_train = IMDB(df_train)\n",
    "df_test = IMDB(df_test)\n",
    "df = IMDB(df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:56:08.244202Z",
     "iopub.execute_input": "2023-03-15T14:56:08.244707Z",
     "iopub.status.idle": "2023-03-15T14:56:09.638553Z",
     "shell.execute_reply.started": "2023-03-15T14:56:08.244662Z",
     "shell.execute_reply": "2023-03-15T14:56:09.637221Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "pad_idx = len(df.vocab.vocabulary)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts = pad_sequence([b[0] for b in batch], padding_value=pad_idx, batch_first=True)\n",
    "    labels = torch.stack([b[1] for b in batch])\n",
    "    \n",
    "    return texts, labels"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:40.914394Z",
     "iopub.execute_input": "2023-03-15T14:47:40.914848Z",
     "iopub.status.idle": "2023-03-15T14:47:40.922853Z",
     "shell.execute_reply.started": "2023-03-15T14:47:40.914766Z",
     "shell.execute_reply": "2023-03-15T14:47:40.921426Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(df_train, batch_size=64, collate_fn=collate_fn, pin_memory=True)\n",
    "test_loader = DataLoader(df_test, batch_size=64, collate_fn=collate_fn, pin_memory=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:40.924621Z",
     "iopub.execute_input": "2023-03-15T14:47:40.925802Z",
     "iopub.status.idle": "2023-03-15T14:47:40.969595Z",
     "shell.execute_reply.started": "2023-03-15T14:47:40.925705Z",
     "shell.execute_reply": "2023-03-15T14:47:40.967851Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_test"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:56:25.397536Z",
     "iopub.execute_input": "2023-03-15T14:56:25.398358Z",
     "iopub.status.idle": "2023-03-15T14:56:25.406230Z",
     "shell.execute_reply.started": "2023-03-15T14:56:25.398306Z",
     "shell.execute_reply": "2023-03-15T14:56:25.404854Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(\n",
    "                    in_channels = 1, \n",
    "                    out_channels = 16, \n",
    "                    kernel_size = (fs, embedding_dim)) \n",
    "                for fs in [2, 3, 4, 5]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(4 * 16, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "\n",
    "        x = [F.max_pool1d(_, _.shape[2]).squeeze(2) for _ in x]\n",
    "\n",
    "        x = self.dropout(torch.cat(x, dim = 1))\n",
    "\n",
    "        return self.fc(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:40.971546Z",
     "iopub.execute_input": "2023-03-15T14:47:40.972075Z",
     "iopub.status.idle": "2023-03-15T14:47:40.986085Z",
     "shell.execute_reply.started": "2023-03-15T14:47:40.972032Z",
     "shell.execute_reply": "2023-03-15T14:47:40.984737Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = TextCNN(vocab_size=len(df.vocab.vocabulary) + 1, embedding_dim=25, pad_idx=pad_idx)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:40.987237Z",
     "iopub.execute_input": "2023-03-15T14:47:40.987593Z",
     "iopub.status.idle": "2023-03-15T14:47:41.013999Z",
     "shell.execute_reply.started": "2023-03-15T14:47:40.987559Z",
     "shell.execute_reply": "2023-03-15T14:47:41.012408Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "vectors = df.vocab.build_vectors(fasttext)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.015771Z",
     "iopub.execute_input": "2023-03-15T14:47:41.016166Z",
     "iopub.status.idle": "2023-03-15T14:47:41.196435Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.016120Z",
     "shell.execute_reply": "2023-03-15T14:47:41.194120Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.embedding.weight.data[:len(vectors)] = torch.from_numpy(vectors)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.198191Z",
     "iopub.execute_input": "2023-03-15T14:47:41.198591Z",
     "iopub.status.idle": "2023-03-15T14:47:41.204990Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.198555Z",
     "shell.execute_reply": "2023-03-15T14:47:41.203596Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc.item()\n",
    "\n",
    "\n",
    "def train(model) -> float:\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    for x, y in tqdm(train_loader, desc='Train'):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += binary_accuracy(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy /= len(train_loader)\n",
    "\n",
    "    return train_loss, train_accuracy"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.206685Z",
     "iopub.execute_input": "2023-03-15T14:47:41.207492Z",
     "iopub.status.idle": "2023-03-15T14:47:41.221057Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.207442Z",
     "shell.execute_reply": "2023-03-15T14:47:41.219474Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for x, y in tqdm(loader, desc='Evaluation'):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += binary_accuracy(output, y)\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "    total_accuracy /= len(loader)\n",
    "\n",
    "    return total_loss, total_accuracy"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.222895Z",
     "iopub.execute_input": "2023-03-15T14:47:41.224294Z",
     "iopub.status.idle": "2023-03-15T14:47:41.236697Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.224226Z",
     "shell.execute_reply": "2023-03-15T14:47:41.235433Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_stats(\n",
    "    train_loss,\n",
    "    valid_loss,\n",
    "    train_accuracy,\n",
    "    valid_accuracy,\n",
    "    title: str\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' accuracy')\n",
    "    \n",
    "    plt.plot(train_accuracy, label='Train accuracy')\n",
    "    plt.plot(valid_accuracy, label='Valid accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.243185Z",
     "iopub.execute_input": "2023-03-15T14:47:41.243819Z",
     "iopub.status.idle": "2023-03-15T14:47:41.258070Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.243715Z",
     "shell.execute_reply": "2023-03-15T14:47:41.256548Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def whole_train_valid_cycle(model, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "    train_accuracy_history, valid_accuracy_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_accuracy = train(model)\n",
    "        valid_loss, valid_accuracy = evaluate(model, test_loader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history, valid_loss_history,\n",
    "            train_accuracy_history, valid_accuracy_history,\n",
    "            title\n",
    "        )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.259372Z",
     "iopub.execute_input": "2023-03-15T14:47:41.260071Z",
     "iopub.status.idle": "2023-03-15T14:47:41.273347Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.260026Z",
     "shell.execute_reply": "2023-03-15T14:47:41.271997Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.275498Z",
     "iopub.execute_input": "2023-03-15T14:47:41.276415Z",
     "iopub.status.idle": "2023-03-15T14:47:41.286221Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.276331Z",
     "shell.execute_reply": "2023-03-15T14:47:41.284903Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:47:41.287699Z",
     "iopub.execute_input": "2023-03-15T14:47:41.288953Z",
     "iopub.status.idle": "2023-03-15T14:47:41.468913Z",
     "shell.execute_reply.started": "2023-03-15T14:47:41.288890Z",
     "shell.execute_reply": "2023-03-15T14:47:41.466769Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:48:58.068825Z",
     "iopub.execute_input": "2023-03-15T14:48:58.069278Z",
     "iopub.status.idle": "2023-03-15T14:48:58.075637Z",
     "shell.execute_reply.started": "2023-03-15T14:48:58.069238Z",
     "shell.execute_reply": "2023-03-15T14:48:58.074111Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "whole_train_valid_cycle(model, 10, 'Text CNN IMDB')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-15T14:56:31.971206Z",
     "iopub.execute_input": "2023-03-15T14:56:31.971922Z",
     "iopub.status.idle": "2023-03-15T15:00:58.826965Z",
     "shell.execute_reply.started": "2023-03-15T14:56:31.971878Z",
     "shell.execute_reply": "2023-03-15T15:00:58.824893Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  12%|███████████████████████▎                                                                                                                                                                  | 88/704 [01:39<08:39,  1.19it/s]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def predict_segmentation(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for x, _ in loader:\n",
    "        output = model(x.to(device)).cpu()\n",
    "\n",
    "        prediction.append(torch.argmax(output, dim=1))\n",
    "\n",
    "    prediction = torch.cat(prediction)\n",
    "\n",
    "    return prediction"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(predict_segmentation(model, test_loader, device), 'prediction.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}