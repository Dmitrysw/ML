{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f7166e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Занятие 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da9159",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 1\n",
    "\n",
    "Как обучают нейронные сети?\n",
    "\n",
    " 1. Быстро\n",
    " 2. Случайно задаем параметры и смотрим на качество\n",
    " 3. Силой\n",
    " 4. С помощью градиентного спуска\n",
    " \n",
    "**Правильный ответ:** мы обучаем нейронные сети с помощью градиентного спуска (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7a85e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 2\n",
    "\n",
    "Что нужно чтобы обучать нейронную сеть?\n",
    "\n",
    " 1. Обучающая выборка\n",
    " 2. Бутерброд с сыром\n",
    " 3. Градиенты функции потерь по параметрам\n",
    " 4. Метод оптимизации\n",
    " 5. Нейронная сеть\n",
    " \n",
    "**Правильный ответ:** для того чтобы обучить нейронную сеть нужна сама нейронная сеть (5), нужны примеры, на которых мы будем ее обучать (1), нужны градиенты функции потерь по параметрам (3) и нужен метод оптимизации, чтобы менять эти самые параметры с помощью алгоритма градиентного спуска (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ddaef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 3\n",
    "\n",
    "Что такое батч?\n",
    "\n",
    " 1. Объекты, для которых будет выполняться подсчет градиентов\n",
    " 2. Объекты, у которых совпадает целевая переменная\n",
    " 3. Объекты, у которых одинаковые признаки\n",
    "\n",
    "**Правильный ответ:** как мы условились на лекции, мы обучаем нейронные сети с помощью градиентного спуска, но не по всей выборке, а по мини-батчам объектов, то есть правильный ответ (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f1e5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 4\n",
    "\n",
    "Какой метод оптимизации объединяет в себе идеи двух других?\n",
    "\n",
    " 1. Adam\n",
    " 2. Momentum\n",
    " 3. AdaGrad\n",
    "\n",
    "**Правильный ответ:** Adam сочетает в себе метод импульса от Momentum и адаптивную длину шага от AdaGrad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f83d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 5\n",
    "\n",
    "Что такое \"метод обратного распространения ошибки\"?\n",
    "\n",
    " 1. Способ подсчитать градиенты функции потерь по параметрам нейронной сети\n",
    " 2. Процесс вычисления промежуточных состояний в нейронной сети\n",
    " 3. Способ выбора лучших объектов для обучения\n",
    "\n",
    "**Правильный ответ:** метод обратного распространения ошибки - алгоритм, в ходе которого мы считаем производные функции потерь по параметрам нейронной сети, чтобы в дальнейшей обучать эти параметры градиентным спуском (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2af66a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 6\n",
    "\n",
    "Расставьте соответствие:\n",
    "\n",
    "(1.1) Вычисление производных и градиентов функции потерь по параметрам нейронной сети\n",
    "(1.2) Вычисление промежуточных состояний и ответа нейронной сети\n",
    "\n",
    "(2.1) backward pass\n",
    "(2.2) forward pass\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Вычисление производных и градиентов функции потерь по параметрам нейронной сети - это backward pass, обратное распространение ошибки.\n",
    "\n",
    "Вычисление промежуточных состояний и ответа нейронной сети - это forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b83700",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 7\n",
    "\n",
    "Пускай мы хотим посчитать градиенты функции потерь по параметрам нашей нейронной сети для того, чтобы сделать шаг градиентного спуска. В каком порядке мы будем это делать?\n",
    "\n",
    " 1. От последних слоев к начальным\n",
    " 2. От начальных слоев к последним\n",
    " 3. От средних слоев в обе стороны\n",
    "\n",
    "**Правильный ответ:** считать градиенты функции потерь по параметрам нейронной сети - метод обратного распространения ошибки, он работает от последних слоев к начальным (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd6b24",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 8\n",
    "\n",
    "Напишите функцию `create_model`, которая должна возвращать полносвязную нейронную сеть из двух слоев. На вход должно быть 100 чисел, на выход 1, посередине 10. В качестве нелинейности используйте ReLU. Воспользуйтесь `nn.Sequential` и передайте слои как последовательность.\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Сделаем все как в условии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(100, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 1)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "e9e0d714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 9\n",
    "\n",
    "Напишите функцию `train`. Она должна принимать на вход нейронную сеть, даталоадер, оптимизатор и функцию потерь. Она должна иметь следующую сигнатуру: `def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):`\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    " 1. Переведите модель в режим обучения.\n",
    " 2. Проитерируйтесь по даталоадеру.\n",
    " 3. На каждой итерации:\n",
    "     - Занулите градиенты с помощью оптимизатора\n",
    "     - Сделайте проход вперед (forward pass)\n",
    "     - Посчитайте ошибку\n",
    "     - Сделайте проход назад (backward pass)\n",
    "     - Напечатайте ошибку на текущем батче с точностью до 5 символов после запятой (только число)\n",
    "     - Сделайте шаг оптимизации\n",
    "\n",
    "Функция должна вернуть среднюю ошибку во время прохода по даталоадеру.\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Сделаем все как в задании:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
    "    model.train()  # переводим модель в режим обучения\n",
    "\n",
    "    total_loss = 0  # создаем переменную для подсчета средней ошибки\n",
    "\n",
    "    for x, y in data_loader:  # итерируемся по даталоадеру\n",
    "        optimizer.zero_grad()  # зануляем градиенты у параметров модели с помощью оптимизатора\n",
    "\n",
    "        output = model(x)  # делаем forward pass на батче объектов\n",
    "\n",
    "        loss = loss_fn(output, y)  # считаем значение функции потерь\n",
    "\n",
    "        loss.backward()  # делаем backward pass - вычисляем значения градиентов для параметров нейронной сети\n",
    "\n",
    "        print(f'{loss.item():.5f}')  # печатаем ошибку на текущем батче с точностью до 5 знаков после запятой\n",
    "\n",
    "        total_loss += loss.item()  # суммируем ошибку\n",
    "\n",
    "        optimizer.step()  # делаем шаг градиентного спуска\n",
    "\n",
    "    return total_loss / len(data_loader)  # возвращаем среднюю ошибку (сумма поделить на количество)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 10\n",
    "\n",
    "Напишите функцию `evaluate`. Она должна принимать на вход нейронную сеть, даталоадер и функцию потерь. Она должна иметь следующую сигнатуру: `def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):`\n",
    "\n",
    "Внутри функции сделайте следующие шаги:\n",
    " 1. Переведите модель в режим инференса (применения)\n",
    " 2. Проитерируйтесь по даталоадеру\n",
    " 3. На каждой итерации:\n",
    "     - Сделайте проход вперед (forward pass)\n",
    "     - Посчитайте ошибку\n",
    "\n",
    "Функция должна вернуть среднюю ошибку во время прохода по даталоадеру.\n",
    "\n",
    "**Правильный ответ:**\n",
    "\n",
    "Сделаем все как в задании:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "@torch.inference_mode()  # декоратор, который выключает в функции подсчет градиентов\n",
    "def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n",
    "    model.eval()  # переводим модель в режим применения\n",
    "\n",
    "    total_loss = 0  # создаем переменную для подсчета средней ошибки\n",
    "\n",
    "    for x, y in data_loader:  # итерируемся по даталоадеру\n",
    "        output = model(x)  # делаем forward pass на батче объектов\n",
    "\n",
    "        loss = loss_fn(output, y)  # считаем значение функции потерь\n",
    "\n",
    "        total_loss += loss.item()  # суммируем ошибку\n",
    "\n",
    "    return total_loss / len(data_loader)  # возвращаем среднюю ошибку (сумма поделить на количество)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# альтернативно выключать градиенты можно так:\n",
    "\n",
    "with torch.no_grad():\n",
    "    ...\n",
    "\n",
    "with torch.inference_mode():\n",
    "    ...\n",
    "\n",
    "@torch.no_grad()\n",
    "def foo():\n",
    "    ...\n",
    "\n",
    "@torch.inference_mode()\n",
    "def foo():\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}